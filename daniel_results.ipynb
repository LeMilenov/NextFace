{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YG4jOi1Rwx2A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading optim config from:  ./optimConfig.ini\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "from optimizer import Optimizer\n",
        "from config import Config\n",
        "import glob\n",
        "import mitsuba as mi\n",
        "sys.path.insert(0,'/content/NextFace') # Verify your path\n",
        "\n",
        "config = Config()\n",
        "config.fillFromDicFile('./optimConfig.ini')\n",
        "# config.device = 'cuda' # torch not compiled with CUDA\n",
        "config.path = './baselMorphableModel/' # Verify your path\n",
        "\n",
        "# Directory path containing all images\n",
        "imageFolderPath = './input/test/s1.png'\n",
        "\n",
        "outputDir = './output/test/all_images/mitsuba_512'\n",
        "#setup\n",
        "if not os.path.exists(outputDir):\n",
        "    os.makedirs(outputDir)  # Create the output directory if it doesn't exist\n",
        "    \n",
        "# torch.cuda.set_device(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Basel Face Model 2017 from ./baselMorphableModel//morphableModel-2017.pickle...\n",
            "loading mesh normals...\n",
            "loading uv parametrization...\n",
            "loading landmarks association file...\n",
            "creating sampler...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\AQ14980\\Desktop\\repos\\NextFace\\faceNext\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[39m=\u001b[39m Optimizer(outputDir, config)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Run the optimization for the current image\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# optimizer.run(imagePath, doStep1=True, doStep2=True, doStep3=True, renderer=\"vertex\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Based on the vertex_based optimization, try to get to the same result with the Mitsuba one\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# optimizer.run(outputImageDir+'/debug/results/ref.png', checkpoint=outputImageDir+'/checkpoints/stage1_output.pickle', doStep1=False, doStep2=True, doStep3=False, renderer=\"mitsuba\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# optimizer.run(imagePath, doStep1=True, doStep2=True, doStep3=True, rendererName=\"redner\")\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# optimizer.run(imagePath, doStep1=True, doStep2=True, doStep3=True, rendererName=\"mitsuba\")\u001b[39;00m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mrun(imageFolderPath, doStep1\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, doStep2\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, doStep3\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, rendererName\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmitsuba\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\AQ14980\\Desktop\\repos\\NextFace\\optimizer.py:49\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, outputDir, config)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvEnhancedRoughness \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrendererName \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mrendererName\n\u001b[1;32m---> 49\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mreloadRenderer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrendererName)\n",
            "File \u001b[1;32mc:\\Users\\AQ14980\\Desktop\\repos\\NextFace\\pipeline.py:164\u001b[0m, in \u001b[0;36mPipeline.reloadRenderer\u001b[1;34m(self, rendererName)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreloadRenderer\u001b[39m(\u001b[39mself\u001b[39m, rendererName):\n\u001b[0;32m    163\u001b[0m     \u001b[39m# TODO clear cache from previous variable ?\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreateRenderer(rendererName)\n",
            "File \u001b[1;32mc:\\Users\\AQ14980\\Desktop\\repos\\NextFace\\pipeline.py:172\u001b[0m, in \u001b[0;36mPipeline.createRenderer\u001b[1;34m(self, rendererName)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39melif\u001b[39;00m rendererName \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmitsuba\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    171\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrendererMitsuba\u001b[39;00m \u001b[39mimport\u001b[39;00m RendererMitsuba\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m RendererMitsuba(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mrtTrainingSamples, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mbounces, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmaxResolution, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmaxResolution) \n\u001b[0;32m    173\u001b[0m \u001b[39melif\u001b[39;00m rendererName \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvertex\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrendererVertexBased\u001b[39;00m \u001b[39mimport\u001b[39;00m RendererVertexBased\n",
            "File \u001b[1;32mc:\\Users\\AQ14980\\Desktop\\repos\\NextFace\\renderers\\rendererMitsuba.py:15\u001b[0m, in \u001b[0;36mRendererMitsuba.__init__\u001b[1;34m(self, samples, bounces, device, screenWidth, screenHeight)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples \u001b[39m=\u001b[39m samples\n\u001b[0;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbounces \u001b[39m=\u001b[39m bounces\n\u001b[1;32m---> 15\u001b[0m \u001b[39massert\u001b[39;00m(device \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# 'we only support GPU computation on mitsuba'\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(device)\n\u001b[0;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "\u001b[1;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "optimizer = Optimizer(outputDir, config)\n",
        "\n",
        "# Run the optimization for the current image\n",
        "# optimizer.run(imagePath, doStep1=True, doStep2=True, doStep3=True, renderer=\"vertex\")\n",
        "# Based on the vertex_based optimization, try to get to the same result with the Mitsuba one\n",
        "# optimizer.run(outputImageDir+'/debug/results/ref.png', checkpoint=outputImageDir+'/checkpoints/stage1_output.pickle', doStep1=False, doStep2=True, doStep3=False, renderer=\"mitsuba\")\n",
        "# optimizer.run(imagePath, doStep1=True, doStep2=True, doStep3=True, rendererName=\"redner\")\n",
        "# optimizer.run(imagePath, doStep1=True, doStep2=True, doStep3=True, rendererName=\"mitsuba\")\n",
        "optimizer.run(imageFolderPath, doStep1=False, doStep2=True, doStep3=False, rendererName=\"mitsuba\")\n",
        "# optimizer.run(imagePath, checkpoint=outputImageDir+'/checkpoints/stage2_output.pickle',doStep1=False, doStep2=False, doStep3=True, renderer=\"mitsuba\")\n",
        "# optimizer.run(imagePath, doStep1=True, doStep2=True, doStep3=False, renderer=\"redner\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from IPython.display import Image\n",
        "\n",
        "# #display results\n",
        "# # Directory containing the images\n",
        "# dir_path = outputDir + 'bikerman_512.jpg/debug/results/'\n",
        "\n",
        "# # Get a list of all the .png images in the directory\n",
        "# image_files = glob.glob(os.path.join(dir_path, \"*.png\"))\n",
        "\n",
        "# # Display each image in turn\n",
        "# for image_file in image_files:\n",
        "#     print(f\"Displaying image: {os.path.basename(image_file)}\")\n",
        "#     display(Image(filename=image_file))\n",
        "# print('2nd ')\n",
        "# # dir_path = outputDir + 'bikerman_256.jpg/debug/results/'\n",
        "\n",
        "# # # Get a list of all the .png images in the directory\n",
        "# # image_files = glob.glob(os.path.join(dir_path, \"*.png\"))\n",
        "\n",
        "# # # Display each image in turn\n",
        "# # for image_file in image_files:\n",
        "# #     print(f\"Displaying image: {os.path.basename(image_file)}\")\n",
        "# #     display(Image(filename=image_file))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # display meshes in polyscope\n",
        "# import polyscope as ps\n",
        "# import trimesh\n",
        "# import glob\n",
        "# import math\n",
        "\n",
        "# display_meshes = [\"mitsuba_step2_iter0.obj\",\"mitsuba_step2_iter400.obj\",\"redner_step2_iter0.obj\",\"redner_step2_iter400.obj\",\"vertex_step2_iter0.obj\",\"vertex_step2_iter400.obj\",]  # replace this with your mesh names\n",
        "\n",
        "# outputDir = './output/test/bikerman_512.jpg/'\n",
        "# # Get a list of all .obj files in the directory\n",
        "# obj_files = glob.glob(os.path.join(outputDir + '/debug/mesh', \"*.obj\"))\n",
        "\n",
        "# # Filter obj_files to only include the ones in display_meshes\n",
        "# obj_files = [file for file in obj_files if os.path.basename(file) in display_meshes]\n",
        "\n",
        "# # Define a folder where the screenshots will be saved\n",
        "# screenshot_folder = outputDir+ \"/debug/screenshot_folder\"  # replace with your desired folder\n",
        "\n",
        "# # Check if the folder exists, if not create it\n",
        "# os.makedirs(screenshot_folder, exist_ok=True)\n",
        "\n",
        "# # Initialize polyscope\n",
        "# ps.init()\n",
        "# # enable auto centering and scaling\n",
        "# # ps.set_autocenter_structures(True)\n",
        "# # ps.set_autoscale_structures(True)\n",
        "# ps.set_up_dir(\"neg_y_up\")\n",
        "# # ps.set_bounding_box(-1.0,2.0)\n",
        "# # ps.set_SSAA_factor(4)\n",
        "# # ps.set_automatically_compute_scene_extents(True)\n",
        "# # ps.set_autoscale_structures(True)\n",
        "# # ps.set_autocenter_structures(True)\n",
        "# # ps.set_ground_plane_height_factor(1.0,True)\n",
        "# ps.set_ground_plane_mode(\"none\")\n",
        "\n",
        "# # # Show the mesh\n",
        "# # ps.show()\n",
        "# # Load and register each mesh to polyscope\n",
        "# for idx, obj_file in enumerate(obj_files):\n",
        "#     # mesh_name = os.path.basename(obj_file)  # get the name of the mesh\n",
        "#     mesh_name = os.path.basename(obj_file)  # get the name of the mesh\n",
        "\n",
        "#     # Load the mesh from an obj file using trimesh\n",
        "#     mesh = trimesh.load_mesh(obj_file)\n",
        "#     # Register the mesh to polyscope\n",
        "#     ps_mesh = ps.register_surface_mesh(mesh_name, mesh.vertices, mesh.faces)\n",
        "#     # Reset the transformation on the mesh\n",
        "#     ps_mesh.reset_transform()\n",
        "#     # Set a color for the mesh\n",
        "#     color = torch.tensor([0.5, 0.5, 0.5]).numpy()  # set a fixed color\n",
        "#     ps_mesh.set_color(color)\n",
        "#     # Reset the view\n",
        "#     ps.reset_camera_to_home_view()\n",
        "#     # Show the mesh\n",
        "#     ps.show()\n",
        "\n",
        "#     # Take a screenshot and save it to the specified folder\n",
        "#     screenshot_name = os.path.join(screenshot_folder, f\"{mesh_name}_screenshot.png\")\n",
        "#     ps.screenshot(screenshot_name)\n",
        "\n",
        "#     # Remove the mesh from polyscope to prepare for the next one\n",
        "#     ps.remove_all_structures()\n",
        "# #display results\n",
        "# # Directory containing the images\n",
        "# dir_path = outputDir + '/debug/screenshot_folder/'\n",
        "\n",
        "# # Get a list of all the .png images in the directory\n",
        "# image_files = glob.glob(os.path.join(dir_path, \"*.png\"))\n",
        "\n",
        "# # Display each image in turn\n",
        "# for image_file in image_files:\n",
        "#     print(f\"Displaying image: {os.path.basename(image_file)}\")\n",
        "#     display(Image(filename=image_file))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
