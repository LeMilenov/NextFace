{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG4jOi1Rwx2A"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0,'/content/NextFace') #verify ur path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNPREJEczUYg"
      },
      "outputs": [],
      "source": [
        "from optimizer import Optimizer\n",
        "from config import Config\n",
        "config = Config()\n",
        "config.fillFromDicFile('./optimConfig.ini')\n",
        "# config.device = 'cuda' # torch not compiled with cuda\n",
        "config.path = './baselMorphableModel/' #verify ur path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwYMbIY00IvC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "imagePath = './input/detailled_faces_unsplash/Bikerman.jpg' #verify ur path\n",
        "outputDir = './output/' + os.path.basename(imagePath.strip('/'))\n",
        "# VALIDATE CUDA\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# # torch.cuda.set_device(torch.cuda.device(0) )\n",
        "# # torch.backends.cudnn.benchmark = False\n",
        "print(torch.cuda.device_count())\n",
        "# torch.cuda.empty_cache()\n",
        "torch.cuda.set_device(0)\n",
        "optimizer = Optimizer(outputDir ,config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5lQYBcXb90iH",
        "outputId": "4ff2113d-6eec-4b77-9d8f-4a32138ea7fc"
      },
<<<<<<< HEAD
      "outputs": [],
=======
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading image from path:  ./input/detailled_faces_unsplash/Bikerman.jpg\n",
            "detecting landmarks using: fan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\AQ14980\\Desktop\\repos\\NextFace\\landmarksfan.py:38: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
            "  return torch.tensor(landmarks, device = self.device)\n",
            "init camera pose...\n",
            "2/3 => Optimizing shape, statistical albedos, expression, head pose and scene light...\n",
            "100%|██████████| 2/2 [00:19<00:00,  9.73s/it]\n",
            "took 0.33 minutes to optimize\n",
            "saving to: ' ./output/Bikerman.jpg/ '. hold on... \n",
            "c:\\Users\\AQ14980\\Desktop\\repos\\NextFace\\faceNext\\lib\\site-packages\\pyredner\\image.py:40: UserWarning: ./output/Bikerman.jpg//roughnessMap_0.png is a low contrast image\n",
            "  skimage.io.imsave(filename,\n"
          ]
        }
      ],
>>>>>>> 56ec937c (wip interpolation)
      "source": [
        "#run the optimization now \n",
        "optimizer.run(imagePath,doStep1=False,doStep2=True, doStep3=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#display results\n",
        "from IPython.display import Image, display\n",
        "from IPython.display import Image\n",
        "import os, glob\n",
        "# Directory containing the images\n",
<<<<<<< HEAD
        "dir_path = outputDir + '/debug/debug_step2/C'\n",
=======
        "dir_path = outputDir + '/debug/debug_step2/B'\n",
>>>>>>> 56ec937c (wip interpolation)
        "\n",
        "# Get a list of all the .png images in the directory\n",
        "image_files = glob.glob(os.path.join(dir_path, \"*.png\"))\n",
        "\n",
        "# Display each image in turn\n",
        "for image_file in image_files:\n",
        "    print(f\"Displaying image: {os.path.basename(image_file)}\")\n",
        "    display(Image(filename=image_file))\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 6,
>>>>>>> 56ec937c (wip interpolation)
      "metadata": {},
      "outputs": [],
      "source": [
        "# # display meshes in polyscope\n",
        "# import polyscope as ps\n",
        "# import trimesh\n",
        "# import glob\n",
        "# import torch\n",
        "# import math\n",
        "\n",
        "# display_meshes = [\"debug1_iter0.obj\", \"debug2_iter0.obj\", \"debug2_iter400.obj\"]  # replace this with your mesh names\n",
        "\n",
        "# # Get a list of all .obj files in the directory\n",
        "# obj_files = glob.glob(os.path.join(outputDir + '/debug/mesh/', \"*.obj\"))\n",
        "\n",
        "# # Filter obj_files to only include the ones in display_meshes\n",
        "# obj_files = [file for file in obj_files if os.path.basename(file) in display_meshes]\n",
        "\n",
        "# # Initialize polyscope\n",
        "# ps.init()\n",
        "\n",
        "# # Flip the axis to Y up\n",
        "# ps.set_up_dir(\"neg_y_up\")\n",
        "\n",
        "# grid_size = int(math.sqrt(len(display_meshes))) + 2  # Grid size based on the number of meshes to display, use square root to get a square grid\n",
        "\n",
        "# mesh_spacing = 150  # Define smaller spacing between meshes\n",
        "\n",
        "# # Calculate the center of the grid\n",
        "# grid_center = mesh_spacing * (grid_size - 1) / 2\n",
        "\n",
        "# # Load and register each mesh to polyscope\n",
        "# for idx, obj_file in enumerate(obj_files):\n",
        "#     mesh_name = os.path.basename(obj_file)  # get the name of the mesh\n",
        "\n",
        "#     # Calculate grid position (i = row, j = column)\n",
        "#     i = idx // grid_size\n",
        "#     j = idx % grid_size\n",
        "\n",
        "#     # Load the mesh from an obj file using trimesh\n",
        "#     mesh = trimesh.load_mesh(obj_file)\n",
        "\n",
        "#     # Add an offset to the x and y coordinates of the vertices to move the mesh\n",
        "#     # Adjust the offsets by subtracting the grid_center to center the grid at the origin\n",
        "#     x_offset = j * mesh_spacing - grid_center  # Offset x-coordinates\n",
        "#     y_offset = i * mesh_spacing - grid_center  # Offset y-coordinates\n",
        "#     mesh.vertices[:, 0] += x_offset\n",
        "#     mesh.vertices[:, 1] += y_offset\n",
        "\n",
        "#     # Register the mesh to polyscope\n",
        "#     ps_mesh = ps.register_surface_mesh(mesh_name, mesh.vertices, mesh.faces)\n",
        "\n",
        "#     # Set a different color for each mesh\n",
        "#     color = torch.rand(3).numpy()  # generate a random color\n",
        "#     ps_mesh.set_color(color)\n",
        "\n",
        "# # Show the mesh\n",
        "# ps.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
